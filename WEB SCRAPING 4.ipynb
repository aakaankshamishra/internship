{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30bd43a3",
   "metadata": {},
   "source": [
    "# Q 10 Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details: A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year Note: - from the home p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dbce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ff3503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25397f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary imports for Beutiful Soup and Selenium library\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "import requests\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "import selenium \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f71708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf8c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95f7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Characters</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>6000</td>\n",
       "      <td>7</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Audiology (Standardized)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>69</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate, Sequential, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>REJAFADA</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>1996</td>\n",
       "      <td>6826</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                         Anonymous Microsoft Web Data   \n",
       "3                                Artificial Characters   \n",
       "4                             Audiology (Standardized)   \n",
       "..                                                 ...   \n",
       "307  Image Recognition Task Execution Times in Mobi...   \n",
       "308                                           REJAFADA   \n",
       "309  Influenza outbreak event prediction via Twitte...   \n",
       "310                      Maternal Health Risk Data Set   \n",
       "311  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                                Data Type                  Task  \\\n",
       "0                           Multivariate        Classification    \n",
       "1                           Multivariate        Classification    \n",
       "2                                          Recommender-Systems    \n",
       "3                           Multivariate        Classification    \n",
       "4                           Multivariate        Classification    \n",
       "..                                    ...                   ...   \n",
       "307  Univariate, Sequential, Time-Series            Regression    \n",
       "308                         Multivariate        Classification    \n",
       "309                         Multivariate        Classification    \n",
       "310                                             Classification    \n",
       "311                           Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of Instances No of Attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2                   Categorical           37711             294   1998   \n",
       "3    Categorical, Integer, Real            6000               7   1992   \n",
       "4                   Categorical             226              69   1992   \n",
       "..                           ...             ...             ...    ...  \n",
       "307                        Real            4000               2   2020   \n",
       "308                     Integer            1996            6826   2020   \n",
       "309               Integer, Real           75840             525   2020   \n",
       "310                                        1014               7   2020   \n",
       "311                        Real            4000               2   2021   \n",
       "\n",
       "[312 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's open the URL\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's navigate to view all dataset\n",
    "try:\n",
    "    dataset=driver.find_element_by_xpath(\"//span[@class='normal']/b/a\")\n",
    "    driver.get(dataset.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    print(\"Span class normal not avlbl\")\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Dataset_Name=[] \n",
    "Data_Type=[]\n",
    "Task=[] \n",
    "Attribute_Type=[] \n",
    "No_of_Instances=[] \n",
    "No_of_Attribute=[] \n",
    "Year=[]\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td/table/tbody/tr/td[2]/p/b/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Name element N/a\")\n",
    "\n",
    "for i in name:\n",
    "    Dataset_Name.append(i.text)\n",
    "try:\n",
    "    names = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td/table/tbody/tr/td[2]/p/b/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Names element N/a\")\n",
    "\n",
    "for i in names:\n",
    "    Dataset_Name.append(i.text)\n",
    "try:\n",
    "    datatype = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[2]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Data Type element N/a\")\n",
    "\n",
    "for i in datatype:\n",
    "    Data_Type.append(i.text)\n",
    "\n",
    "try:\n",
    "    task = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[3]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Task element N/a\")\n",
    "\n",
    "for i in task:\n",
    "    Task.append(i.text)\n",
    "\n",
    "try:    \n",
    "    att = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[4]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Attribute element N/a\")\n",
    "\n",
    "for i in att:\n",
    "    Attribute_Type.append(i.text)\n",
    "\n",
    "try:    \n",
    "    ins = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[5]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Instances element N/a\")\n",
    "    \n",
    "for i in ins:\n",
    "    No_of_Instances.append(i.text)\n",
    "\n",
    "try:    \n",
    "    no_of_att = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[6]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Attribute element N/a\")\n",
    "    \n",
    "for i in no_of_att:\n",
    "    No_of_Attribute.append(i.text)\n",
    "try:\n",
    "    year = driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr[2]/td[7]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Year element N/a\")\n",
    "\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "\n",
    "try:\n",
    "    datatype = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[2]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Datatype element N/a\")\n",
    "\n",
    "for i in datatype:\n",
    "    Data_Type.append(i.text)\n",
    "\n",
    "try:\n",
    "    tsk = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[3]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Task element N/a\")\n",
    "\n",
    "for i in tsk:\n",
    "    Task.append(i.text)\n",
    "try:\n",
    "    attr = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[4]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Attribute element N/a\")\n",
    "\n",
    "for i in attr:\n",
    "    Attribute_Type.append(i.text)\n",
    "try:\n",
    "    noi = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[5]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Instance element N/a\")\n",
    "\n",
    "for i in noi:\n",
    "    No_of_Instances.append(i.text)\n",
    "try:\n",
    "    noa = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[6]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Number of Attribute element N/a\")\n",
    "\n",
    "for i in noa:\n",
    "    No_of_Attribute.append(i.text)\n",
    "try:\n",
    "    yr = driver.find_elements_by_xpath('//tr[@bgcolor=\"DDEEFF\"]/td[7]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Year element N/a\")\n",
    "\n",
    "for i in yr:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "UCI_DF=pd.DataFrame({})\n",
    "UCI_DF['Dataset Name']=Dataset_Name \n",
    "UCI_DF['Data Type']=Data_Type\n",
    "UCI_DF['Task']=Task\n",
    "UCI_DF['Attribute Type']=Attribute_Type\n",
    "UCI_DF['No of Instances']=No_of_Instances\n",
    "UCI_DF['No of Attribute']= No_of_Attribute\n",
    "UCI_DF['Year']=Year\n",
    "UCI_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01c919",
   "metadata": {},
   "source": [
    "# Q9 Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Vot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47533863",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88fa4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835a7865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,000,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,052,991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>951,904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>284,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>244,269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48,981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>59,712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>191,180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40,426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>229,839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,000,834  \n",
       "1    51 min     8.7  1,052,991  \n",
       "2    44 min     8.2    951,904  \n",
       "3    60 min     7.5    284,500  \n",
       "4    43 min     7.6    244,269  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     48,981  \n",
       "96   50 min     7.8     59,712  \n",
       "97   42 min     8.1    191,180  \n",
       "98   45 min     7.1     40,426  \n",
       "99  572 min     8.6    229,839  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's open the URL\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Name=[]\n",
    "Year_Span=[] \n",
    "Genre=[] \n",
    "Run_Time=[] \n",
    "Ratings=[] \n",
    "Votes=[]\n",
    "\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Name element N/a\")\n",
    "\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "try:\n",
    "    year = driver.find_elements_by_xpath('//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Year span element N/a\")\n",
    "\n",
    "for i in year:\n",
    "    Year_Span.append(i.text)\n",
    "try:\n",
    "    gen = driver.find_elements_by_xpath('//span[@class=\"genre\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Genre element N/a\")\n",
    "\n",
    "for i in gen:\n",
    "    Genre.append(i.text)\n",
    "try:\n",
    "    runtime = driver.find_elements_by_xpath('//span[@class=\"runtime\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Runtime element N/a\")\n",
    "\n",
    "    \n",
    "for i in runtime:\n",
    "    Run_Time.append(i.text)\n",
    "try:\n",
    "    ratings = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Rating element N/a\")\n",
    "\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "try:\n",
    "    vote = driver.find_elements_by_xpath('//span[@name=\"nv\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Vote element N/a\")\n",
    "\n",
    "for i in vote:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "IMDB_DF=pd.DataFrame({})\n",
    "IMDB_DF['Name']=Name\n",
    "IMDB_DF['Year Span']= Year_Span\n",
    "IMDB_DF['Genre']=Genre\n",
    "IMDB_DF['Run Time']= Run_Time\n",
    "IMDB_DF['Ratings']=Ratings\n",
    "IMDB_DF['Votes']=Votes\n",
    "IMDB_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a7e1b",
   "metadata": {},
   "source": [
    "# Q8.Scrape the details of Highest selling novels. Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/ You have to find the following details: A) Book name B) Author name C) Volumes sold D) Publisher E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5660bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8826b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc9731c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's open the URL\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Book_Name=[] \n",
    "Author_Name=[] \n",
    "Volumes_Sold=[]\n",
    "Publisher=[] \n",
    "Genre=[]\n",
    "\n",
    "# scrape the data as required\n",
    "try:\n",
    "    book = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Book element N/a\")\n",
    "\n",
    "for i in book:\n",
    "    Book_Name.append(i.text)\n",
    "try:\n",
    "    author = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Author element N/a\")\n",
    "\n",
    "for i in author:\n",
    "    Author_Name.append(i.text)\n",
    "try:\n",
    "    vol = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Volumes element N/a\")\n",
    "\n",
    "for i in vol:\n",
    "    Volumes_Sold.append(i.text)\n",
    "try:\n",
    "    pub = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Publisher element N/a\")\n",
    "\n",
    "for i in pub:\n",
    "    Publisher.append(i.text)\n",
    "try:\n",
    "    gen = driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Genre element N/a\")\n",
    "\n",
    "for i in gen:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "# Let's create the dataframe from the scraped data\n",
    "Novel_DF=pd.DataFrame({})\n",
    "Novel_DF['Book Name']=Book_Name\n",
    "Novel_DF['Author Name']= Author_Name\n",
    "Novel_DF['Volumes Sold']=Volumes_Sold\n",
    "Novel_DF['Publisher']=Publisher\n",
    "Novel_DF['Genre']=Genre\n",
    "Novel_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22a9f5",
   "metadata": {},
   "source": [
    "# Q5 .Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details: A) Repository title B) Repository description C) Contributors count D) Language use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8520f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d65e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4b93f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 25 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatVodTVOfficial / TVBoxOSC</td>\n",
       "      <td>开发阶段请不要提没有意义的PR，也不要用PR来提意见！</td>\n",
       "      <td>10</td>\n",
       "      <td>[Java, CSS, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meituan / YOLOv6</td>\n",
       "      <td>YOLOv6: a single-stage object detection framew...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public-apis / public-apis</td>\n",
       "      <td>A collective list of free APIs</td>\n",
       "      <td>1,268</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gophish / gophish</td>\n",
       "      <td>Open-Source Phishing Toolkit</td>\n",
       "      <td>44</td>\n",
       "      <td>[Go, JavaScript, HTML, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>by</td>\n",
       "      <td>[1,965, 1,954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>faif / python-patterns</td>\n",
       "      <td>A collection of design patterns/idioms in Python</td>\n",
       "      <td>107</td>\n",
       "      <td>[Python, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x2bool / xlite</td>\n",
       "      <td>SQLite extension to query Excel (.xlsx, .xls, ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Rust, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YuanHsing / freed</td>\n",
       "      <td>《Software Engineering at Google》的中文翻译版本</td>\n",
       "      <td>-</td>\n",
       "      <td>[2, YuanHsing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qiangmzsx / Software-Engineering-at-Google</td>\n",
       "      <td>Linux, Jenkins, AWS, SRE, Prometheus, Docker, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bregman-arie / devops-exercises</td>\n",
       "      <td>猫影视TV（停运）---&gt; TVbox（空壳）</td>\n",
       "      <td>92</td>\n",
       "      <td>[Python, HTML, Groovy, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>liu673cn / mao</td>\n",
       "      <td>Haptic input knob with software-defined endsto...</td>\n",
       "      <td>-</td>\n",
       "      <td>[HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>scottbez1 / smartknob</td>\n",
       "      <td>RuoYi-Vue 全新 Cloud 版本，优化重构所有功能。基于 Spring Cloud...</td>\n",
       "      <td>2</td>\n",
       "      <td>[C++, C, Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>YunaiV / yudao-cloud</td>\n",
       "      <td>A tiny little drawing app.</td>\n",
       "      <td>20</td>\n",
       "      <td>[Java, PLpgSQL, TSQL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tldraw / tldraw</td>\n",
       "      <td>📝 Algorithms and data structures implemented i...</td>\n",
       "      <td>57</td>\n",
       "      <td>[TypeScript, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>trekhleb / javascript-algorithms</td>\n",
       "      <td>🛠「Watt Toolkit」是一个开源跨平台的多功能 Steam 工具箱。</td>\n",
       "      <td>192</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BeyondDimension / SteamTools</td>\n",
       "      <td>Roadmap to becoming a developer in 2022</td>\n",
       "      <td>9</td>\n",
       "      <td>[C#, Rich, Format, JavaScript, Kotlin, PowerSh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kamranahmedse / developer-roadmap</td>\n",
       "      <td>Lean's OpenWrt source</td>\n",
       "      <td>155</td>\n",
       "      <td>[TypeScript, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>coolsnowwolf / lede</td>\n",
       "      <td>All Algorithms implemented in Rust</td>\n",
       "      <td>293</td>\n",
       "      <td>[C, Makefile, Shell, Roff, Perl, M4, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TheAlgorithms / Rust</td>\n",
       "      <td>A server software reimplementation for a certa...</td>\n",
       "      <td>112</td>\n",
       "      <td>[Rust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Grasscutters / Grasscutter</td>\n",
       "      <td>🏡 Open source home automation that puts local ...</td>\n",
       "      <td>121</td>\n",
       "      <td>[Java, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>home-assistant / core</td>\n",
       "      <td>ALL IN ONE Hacking Tool For Hackers</td>\n",
       "      <td>2,894</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Z4nzu / hackingtool</td>\n",
       "      <td>Tooll 3 is an open source software to create r...</td>\n",
       "      <td>21</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>still-scene / t3</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>5</td>\n",
       "      <td>[C#, HLSL, C++]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ossu / computer-science</td>\n",
       "      <td>neovim lsp plugin</td>\n",
       "      <td>No</td>\n",
       "      <td>[122, 111]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Repository Title  \\\n",
       "0                  CatVodTVOfficial / TVBoxOSC   \n",
       "1                             meituan / YOLOv6   \n",
       "2                    public-apis / public-apis   \n",
       "3                            gophish / gophish   \n",
       "4     EbookFoundation / free-programming-books   \n",
       "5                       faif / python-patterns   \n",
       "6                               x2bool / xlite   \n",
       "7                            YuanHsing / freed   \n",
       "8   qiangmzsx / Software-Engineering-at-Google   \n",
       "9              bregman-arie / devops-exercises   \n",
       "10                              liu673cn / mao   \n",
       "11                       scottbez1 / smartknob   \n",
       "12                        YunaiV / yudao-cloud   \n",
       "13                             tldraw / tldraw   \n",
       "14            trekhleb / javascript-algorithms   \n",
       "15                BeyondDimension / SteamTools   \n",
       "16           kamranahmedse / developer-roadmap   \n",
       "17                         coolsnowwolf / lede   \n",
       "18                        TheAlgorithms / Rust   \n",
       "19                  Grasscutters / Grasscutter   \n",
       "20                       home-assistant / core   \n",
       "21                         Z4nzu / hackingtool   \n",
       "22                            still-scene / t3   \n",
       "23                     ossu / computer-science   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0                         开发阶段请不要提没有意义的PR，也不要用PR来提意见！                 10   \n",
       "1   YOLOv6: a single-stage object detection framew...                 11   \n",
       "2                      A collective list of free APIs              1,268   \n",
       "3                        Open-Source Phishing Toolkit                 44   \n",
       "4                📚 Freely available programming books                 by   \n",
       "5    A collection of design patterns/idioms in Python                107   \n",
       "6   SQLite extension to query Excel (.xlsx, .xls, ...                  -   \n",
       "7             《Software Engineering at Google》的中文翻译版本                  -   \n",
       "8   Linux, Jenkins, AWS, SRE, Prometheus, Docker, ...                 10   \n",
       "9                             猫影视TV（停运）---> TVbox（空壳）                 92   \n",
       "10  Haptic input knob with software-defined endsto...                  -   \n",
       "11  RuoYi-Vue 全新 Cloud 版本，优化重构所有功能。基于 Spring Cloud...                  2   \n",
       "12                         A tiny little drawing app.                 20   \n",
       "13  📝 Algorithms and data structures implemented i...                 57   \n",
       "14             🛠「Watt Toolkit」是一个开源跨平台的多功能 Steam 工具箱。                192   \n",
       "15            Roadmap to becoming a developer in 2022                  9   \n",
       "16                              Lean's OpenWrt source                155   \n",
       "17                 All Algorithms implemented in Rust                293   \n",
       "18  A server software reimplementation for a certa...                112   \n",
       "19  🏡 Open source home automation that puts local ...                121   \n",
       "20                ALL IN ONE Hacking Tool For Hackers              2,894   \n",
       "21  Tooll 3 is an open source software to create r...                 21   \n",
       "22  🎓 Path to a free self-taught education in Comp...                  5   \n",
       "23                                  neovim lsp plugin                 No   \n",
       "\n",
       "                                        Language Used  \n",
       "0                                  [Java, CSS, Other]  \n",
       "1                                     [Python, Shell]  \n",
       "2                                     [Python, Shell]  \n",
       "3                       [Go, JavaScript, HTML, Other]  \n",
       "4                                      [1,965, 1,954]  \n",
       "5                                  [Python, Makefile]  \n",
       "6                                           [Rust, C]  \n",
       "7                                      [2, YuanHsing]  \n",
       "8                                              [HTML]  \n",
       "9                       [Python, HTML, Groovy, Shell]  \n",
       "10                                             [HTML]  \n",
       "11                            [C++, C, Python, Shell]  \n",
       "12                              [Java, PLpgSQL, TSQL]  \n",
       "13                    [TypeScript, JavaScript, Other]  \n",
       "14                                       [JavaScript]  \n",
       "15  [C#, Rich, Format, JavaScript, Kotlin, PowerSh...  \n",
       "16                    [TypeScript, JavaScript, Other]  \n",
       "17        [C, Makefile, Shell, Roff, Perl, M4, Other]  \n",
       "18                                             [Rust]  \n",
       "19                                      [Java, Other]  \n",
       "20                                           [Python]  \n",
       "21                                    [Python, Shell]  \n",
       "22                                    [C#, HLSL, C++]  \n",
       "23                                         [122, 111]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's define the url\n",
    "url=('https://github.com/')\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "try:\n",
    "    link_trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a').get_attribute('href')\n",
    "except NoSuchElementException:\n",
    "    print(\"Trending xpath could not be found\")\n",
    "\n",
    "driver.get(link_trending)\n",
    "time.sleep(5)\n",
    "# Let's create an empty lists to store scraping data\n",
    "Repository_Title=[]\n",
    "Repository_Description=[] \n",
    "Contributors_Count=[] \n",
    "Language_Used=[]\n",
    "urls=[]\n",
    "\n",
    "# Let's create a function\n",
    "try:\n",
    "    rep_title=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/h1/a')\n",
    "except NoSuchElementException:\n",
    "    print(\"Title xpath could not be found\")\n",
    "try:\n",
    "    descriptions=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/p')\n",
    "except NoSuchElementException:\n",
    "    print(\"Description xpath could not be found\")\n",
    "for i in [rep_title,descriptions]:\n",
    "    for j in i:\n",
    "        if i ==rep_title:\n",
    "            Repository_Title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==descriptions:\n",
    "            Repository_Description.append(j.text)\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    div_list=driver.find_elements_by_xpath('//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    try:\n",
    "        Contributors_Count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_Count.append('-')\n",
    "    try:\n",
    "        Language_Used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_Used.append('-')\n",
    "\n",
    "# Let's check the length of the scrape data        \n",
    "print(len(Repository_Title),len(Repository_Description),len(Contributors_Count),len(Language_Used))\n",
    "\n",
    "\n",
    "# L3t's create the dataframe from the scraped data\n",
    "Repositoriy=pd.DataFrame({})\n",
    "Repositoriy['Repository Title']=Repository_Title[0:24]\n",
    "Repositoriy['Repository Description']=Repository_Description[0:24]\n",
    "Repositoriy['Contributors Count']=Contributors_Count[0:24]\n",
    "Repositoriy['Language Used']=Language_Used[0:24]\n",
    "Repositoriy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06613f",
   "metadata": {},
   "source": [
    "# 4 .Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank B) State C) GSDP(18-19) D) GSDP(17-18) E) Share(2017) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20c57252",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ebc1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7ae0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get( 'http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "680f5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting heading of econamy\n",
    "economy=driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/button')\n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34a3a616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.statisticstimes.com/economy/india-statistics.php'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting subtitle india\n",
    "india=driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "url=india.get_attribute('href')\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93e324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url for India\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72b5c909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.statisticstimes.com/economy/india/indian-states-gdp.php'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting India state GDP url\n",
    "GDP=driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "India_GDP=GDP.get_attribute('href')\n",
    "India_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1502cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting rank data\n",
    "Rank=[]\n",
    "try:\n",
    "    rank=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')\n",
    "#extracting state data\n",
    "State=[]\n",
    "try:\n",
    "    state=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('-')\n",
    "#extracting GDP current price(18-19) data\n",
    "GSDP_price18=[]\n",
    "try:\n",
    "    gsdp=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for i in gsdp:\n",
    "        GSDP_price18.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_price18.append('-')\n",
    "#extracting GDP (19-20) current price data\n",
    "GSDP_price=[]\n",
    "try:\n",
    "    gsdp=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "    for i in gsdp:\n",
    "        GSDP_price.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_price.append('-')\n",
    "len(GSDP_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acb1c6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP Current Price(19-20)</th>\n",
       "      <th>GSDP Current Price(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>13.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>8.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>8.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>7.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>7.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>5.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>4.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>4.56%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>4.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>4.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>4.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>3.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>2.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>2.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>2.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>1.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>1.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>1.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>1.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>0.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>0.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>0.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>0.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>0.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>0.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>0.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>0.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>0.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>0.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP Current Price(19-20)  \\\n",
       "0     1                Maharashtra                         -   \n",
       "1     2                 Tamil Nadu                 1,845,853   \n",
       "2     3              Uttar Pradesh                 1,687,818   \n",
       "3     4                    Gujarat                         -   \n",
       "4     5                  Karnataka                 1,631,977   \n",
       "5     6                West Bengal                 1,253,832   \n",
       "6     7                  Rajasthan                 1,020,989   \n",
       "7     8             Andhra Pradesh                   972,782   \n",
       "8     9                  Telangana                   969,604   \n",
       "9    10             Madhya Pradesh                   906,672   \n",
       "10   11                     Kerala                         -   \n",
       "11   12                      Delhi                   856,112   \n",
       "12   13                    Haryana                   831,610   \n",
       "13   14                      Bihar                   611,804   \n",
       "14   15                     Punjab                   574,760   \n",
       "15   16                     Odisha                   521,275   \n",
       "16   17                      Assam                         -   \n",
       "17   18               Chhattisgarh                   329,180   \n",
       "18   19                  Jharkhand                   328,598   \n",
       "19   20                Uttarakhand                         -   \n",
       "20   21            Jammu & Kashmir                         -   \n",
       "21   22           Himachal Pradesh                   165,472   \n",
       "22   23                        Goa                    80,449   \n",
       "23   24                    Tripura                    55,984   \n",
       "24   25                 Chandigarh                         -   \n",
       "25   26                 Puducherry                    38,253   \n",
       "26   27                  Meghalaya                    36,572   \n",
       "27   28                     Sikkim                    32,496   \n",
       "28   29                    Manipur                    31,790   \n",
       "29   30                   Nagaland                         -   \n",
       "30   31          Arunachal Pradesh                         -   \n",
       "31   32                    Mizoram                    26,503   \n",
       "32   33  Andaman & Nicobar Islands                         -   \n",
       "\n",
       "   GSDP Current Price(18-19) Share(18-19) GDP($ Billion)  \n",
       "0                  2,632,792       13.94%         13.94%  \n",
       "1                  1,630,208        8.63%          8.63%  \n",
       "2                  1,584,764        8.39%          8.39%  \n",
       "3                  1,502,899        7.96%          7.96%  \n",
       "4                  1,493,127        7.91%          7.91%  \n",
       "5                  1,089,898        5.77%          5.77%  \n",
       "6                    942,586        4.99%          4.99%  \n",
       "7                    862,957        4.57%          4.57%  \n",
       "8                    861,031        4.56%          4.56%  \n",
       "9                    809,592        4.29%          4.29%  \n",
       "10                   781,653        4.14%          4.14%  \n",
       "11                   774,870        4.10%          4.10%  \n",
       "12                   734,163        3.89%          3.89%  \n",
       "13                   530,363        2.81%          2.81%  \n",
       "14                   526,376        2.79%          2.79%  \n",
       "15                   487,805        2.58%          2.58%  \n",
       "16                   315,881        1.67%          1.67%  \n",
       "17                   304,063        1.61%          1.61%  \n",
       "18                   297,204        1.57%          1.57%  \n",
       "19                   245,895        1.30%          1.30%  \n",
       "20                   155,956        0.83%          0.83%  \n",
       "21                   153,845        0.81%          0.81%  \n",
       "22                    73,170        0.39%          0.39%  \n",
       "23                    49,845        0.26%          0.26%  \n",
       "24                    42,114        0.22%          0.22%  \n",
       "25                    34,433        0.18%          0.18%  \n",
       "26                    33,481        0.18%          0.18%  \n",
       "27                    28,723        0.15%          0.15%  \n",
       "28                    27,870        0.15%          0.15%  \n",
       "29                    27,283        0.14%          0.14%  \n",
       "30                    24,603        0.13%          0.13%  \n",
       "31                    22,287        0.12%          0.12%  \n",
       "32                         -            -              -  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting share price(18-19) data\n",
    "Share=[]\n",
    "try:\n",
    "    share=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('-')\n",
    "#extracting GDP billion data\n",
    "GDP_billion=[]\n",
    "try:\n",
    "    billion=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for i in billion:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append('-')\n",
    "# creating data frame\n",
    "df=pd.DataFrame({})\n",
    "\n",
    "df['Rank']=Rank\n",
    "df['State']=State\n",
    "df['GSDP Current Price(19-20)']=GSDP_price\n",
    "df['GSDP Current Price(18-19)']=GSDP_price18\n",
    "df['Share(18-19)']=Share\n",
    "df['GDP($ Billion)']=GDP_billion\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffbe9d",
   "metadata": {},
   "source": [
    "# Q3 Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name B) Description Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5013092",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0ec492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f156752",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.guru99.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f820ee73",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: cannot determine loading status\nfrom unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.53)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00396463+2188387]\n\tOrdinal0 [0x0032E461+1762401]\n\tOrdinal0 [0x00243D78+802168]\n\tOrdinal0 [0x00237210+750096]\n\tOrdinal0 [0x0023675A+747354]\n\tOrdinal0 [0x00235D3F+744767]\n\tOrdinal0 [0x00234C28+740392]\n\tOrdinal0 [0x00235228+741928]\n\tOrdinal0 [0x0023F153+782675]\n\tOrdinal0 [0x00249FBB+827323]\n\tOrdinal0 [0x0024D310+840464]\n\tOrdinal0 [0x002354F6+742646]\n\tOrdinal0 [0x00249BF3+826355]\n\tOrdinal0 [0x0029CF6D+1167213]\n\tOrdinal0 [0x0028C5F6+1099254]\n\tOrdinal0 [0x00266BE0+945120]\n\tOrdinal0 [0x00267AD6+948950]\n\tGetHandleVerifier [0x006371F2+2712546]\n\tGetHandleVerifier [0x0062886D+2652765]\n\tGetHandleVerifier [0x0042002A+520730]\n\tGetHandleVerifier [0x0041EE06+516086]\n\tOrdinal0 [0x0033468B+1787531]\n\tOrdinal0 [0x00338E88+1805960]\n\tOrdinal0 [0x00338F75+1806197]\n\tOrdinal0 [0x00341DF1+1842673]\n\tBaseThreadInitThunk [0x75EB6359+25]\n\tRtlGetAppContainerNamedObjectPath [0x774F87A4+228]\n\tRtlGetAppContainerNamedObjectPath [0x774F8774+180]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11760/68871222.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//a[@title=\"Selenium\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#getting web element and clicking.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#Creating empty list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    708\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.53)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00396463+2188387]\n\tOrdinal0 [0x0032E461+1762401]\n\tOrdinal0 [0x00243D78+802168]\n\tOrdinal0 [0x00237210+750096]\n\tOrdinal0 [0x0023675A+747354]\n\tOrdinal0 [0x00235D3F+744767]\n\tOrdinal0 [0x00234C28+740392]\n\tOrdinal0 [0x00235228+741928]\n\tOrdinal0 [0x0023F153+782675]\n\tOrdinal0 [0x00249FBB+827323]\n\tOrdinal0 [0x0024D310+840464]\n\tOrdinal0 [0x002354F6+742646]\n\tOrdinal0 [0x00249BF3+826355]\n\tOrdinal0 [0x0029CF6D+1167213]\n\tOrdinal0 [0x0028C5F6+1099254]\n\tOrdinal0 [0x00266BE0+945120]\n\tOrdinal0 [0x00267AD6+948950]\n\tGetHandleVerifier [0x006371F2+2712546]\n\tGetHandleVerifier [0x0062886D+2652765]\n\tGetHandleVerifier [0x0042002A+520730]\n\tGetHandleVerifier [0x0041EE06+516086]\n\tOrdinal0 [0x0033468B+1787531]\n\tOrdinal0 [0x00338E88+1805960]\n\tOrdinal0 [0x00338F75+1806197]\n\tOrdinal0 [0x00341DF1+1842673]\n\tBaseThreadInitThunk [0x75EB6359+25]\n\tRtlGetAppContainerNamedObjectPath [0x774F87A4+228]\n\tRtlGetAppContainerNamedObjectPath [0x774F8774+180]\n"
     ]
    }
   ],
   "source": [
    "#getting web element and clicking.\n",
    "driver.find_element_by_xpath('//a[@title=\"Selenium\"]').click()\n",
    "#getting web element and clicking.\n",
    "driver.find_element_by_xpath('//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]').click()\n",
    "#Creating empty list.\n",
    "Name=[]\n",
    "Description=[]\n",
    "#Creating for loop for Name to scrape data.\n",
    "dt=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
    "for d in dt:\n",
    "    Name.append(d.text)\n",
    "    \n",
    "#Creating for loop for Description to scrape data.\n",
    "dt=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "for d in dt:\n",
    "    Description.append(d.text)\n",
    "#Creating dataframe\n",
    "df=pd.DataFrame({})\n",
    "\n",
    "df['Name']=Name[:41]\n",
    "df['Description']=Description[:41]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc598d6f",
   "metadata": {},
   "source": [
    "# Q2 .Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1 st ODI) B) Series C) Place D) Date E) Time Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b7c89a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83c35818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ec41221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary imports for Beutiful Soup and Selenium library\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "import requests\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "import selenium \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c91d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ef508bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "088e5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the  bcci link to the driver to load in the browser\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4690c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "international_fix=driver.find_element_by_xpath('/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "international_fix.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f80e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "time = []\n",
    "series = []\n",
    "place = []\n",
    "match_title = []\n",
    "match_details = []\n",
    "\n",
    "# MERging Month and Day together for Date OBject\n",
    "try :\n",
    "    month_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__month\"]')\n",
    "    day_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__date\"]')\n",
    "    for i in range(len(month_obj)):\n",
    "        date.append(str(day_obj[i].text)+'-'+str(month_obj[i].text).lower())\n",
    "except NoSuchElementException:\n",
    "    date.append('-')\n",
    "    \n",
    "    \n",
    "# Time of match  \n",
    "\n",
    "try :\n",
    "    time_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__time\"]')\n",
    "    \n",
    "    for i in range(len(time_obj)):\n",
    "        time.append(str(time_obj[i].text))\n",
    "except NoSuchElementException:\n",
    "    time.append('-')\n",
    "\n",
    "    \n",
    "#series details and Match Tittle\n",
    "\n",
    "try :\n",
    "    series_obj = driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__format\"]')\n",
    "    title_obj = driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]')\n",
    "    for i in range(len(month_obj)):\n",
    "        series.append(str(series_obj[i].text)+' '+str(title_obj[i].text))\n",
    "        match_title.append(str(title_obj[i].text))\n",
    "except NoSuchElementException:\n",
    "    series.append('-')\n",
    "    \n",
    "# Location of MAtch, and series information\n",
    "\n",
    "try :\n",
    "    location_obj = driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span')\n",
    "    match_name_obj = driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "    for i in range(len(time_obj)):\n",
    "        place.append(str(location_obj[i].text))\n",
    "        match_details.append(match_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    place.append ('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "439a928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Match</th>\n",
       "      <th>Match Location</th>\n",
       "      <th>series details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, Series, Match, Match Location, series details]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dictionary of the elements\n",
    "dict= {\n",
    "    'Date':date,'Time':time,'Series':series,'Match': match_title,'Match Location':place,\n",
    "    'series details': match_details\n",
    "}\n",
    "\n",
    "#table creating with creating a DataFrame\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c144e46",
   "metadata": {},
   "source": [
    "# Q1 Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank B) Name C) Artist D) Upload date E) Views\n",
    "\n",
    "Scrape the details team India’s international fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b503a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d787a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f4d7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading url to the chrome driver\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f651a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "#creating list for rank, uploader)name, video name, no of views, date of upload\n",
    "rank = []\n",
    "video_names = []\n",
    "video_uploader_name = []\n",
    "views = []\n",
    "upload_dates = []\n",
    "\n",
    "\n",
    "    #RANK ELEMENT\n",
    "try:\n",
    "    rank_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')[:30]\n",
    "    for i in rank_obj:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')\n",
    "    \n",
    "    \n",
    "   #VIDEO NAME ELEMENT\n",
    "try:\n",
    "    videoname_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')[:30]\n",
    "    for i in videoname_obj:\n",
    "        video_names.append(i.text.split('[')[0][1:-1])\n",
    "except NoSuchElementException :\n",
    "    video_names.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #UPLOADER_OF_VIDEO\n",
    "try:\n",
    "    uploader_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[:30]\n",
    "    for i in uploader_obj:\n",
    "        video_uploader_name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    video_uploader_name.append('-')\n",
    "    \n",
    "    \n",
    "\n",
    "    #VIEWS ON THE VIDEOS\n",
    "try:\n",
    "    view_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')[:30]\n",
    "    for i in view_obj:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    views.append('-')\n",
    "    \n",
    "#DATE OF THE VIDEO ELEMENT\n",
    "try:\n",
    "    date_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')[:30]\n",
    "    for i in date_obj:\n",
    "        upload_dates.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    upload_dates.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de19e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>video_name</th>\n",
       "      <th>uploader</th>\n",
       "      <th>Views in Billions</th>\n",
       "      <th>upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>10.84</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.88</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.38</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.75</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.55</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.46</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.69</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.60</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.58</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.50</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.46</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.14</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.96</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.71</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.60</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.59</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.56</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.46</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.40</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.30</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.30</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.29</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.27</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.25</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.22</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.22</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.19</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.18</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.17</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>3.10</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                 video_name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.                                  Bath Song   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                                Uptown Funk   \n",
       "8    9.  Learning Colors – Colorful Eggs on a Farm   \n",
       "9   10.   Masha and the Bear – Recipe for Disaster   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.                          Wheels on the Bus   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                      Sugar   \n",
       "14  15.                                       Roar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                                      Sorry   \n",
       "17  18.                          Thinking Out Loud   \n",
       "18  19.                                     Axel F   \n",
       "19  20.                             Girls Like You   \n",
       "20  21.                                      Faded   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                        Baa Baa Black Sheep   \n",
       "23  24.                                 Let Her Go   \n",
       "24  25.                                   Bailando   \n",
       "25  26.                                    Lean On   \n",
       "26  27.                                    Perfect   \n",
       "27  28.                               Shake It Off   \n",
       "28  29.           Waka Waka (This Time for Africa)   \n",
       "29  30.                                   Mi Gente   \n",
       "\n",
       "                                       uploader Views in Billions  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories             10.84   \n",
       "1                                    Luis Fonsi              7.88   \n",
       "2                                   LooLoo Kids              6.38   \n",
       "3                                    Ed Sheeran              5.75   \n",
       "4                                   Wiz Khalifa              5.55   \n",
       "5                    Cocomelon – Nursery Rhymes              5.46   \n",
       "6                                     ChuChu TV              4.69   \n",
       "7                                   Mark Ronson              4.60   \n",
       "8                                   Miroshka TV              4.58   \n",
       "9                                    Get Movies              4.50   \n",
       "10                                          Psy              4.46   \n",
       "11                   Cocomelon – Nursery Rhymes              4.14   \n",
       "12                                    El Chombo              3.96   \n",
       "13                                     Maroon 5              3.71   \n",
       "14                                   Katy Perry              3.60   \n",
       "15                                  OneRepublic              3.59   \n",
       "16                                Justin Bieber              3.56   \n",
       "17                                   Ed Sheeran              3.46   \n",
       "18                                   Crazy Frog              3.40   \n",
       "19                                     Maroon 5              3.30   \n",
       "20                                  Alan Walker              3.30   \n",
       "21                                   Katy Perry              3.29   \n",
       "22                   Cocomelon – Nursery Rhymes              3.27   \n",
       "23                                    Passenger              3.25   \n",
       "24                             Enrique Iglesias              3.22   \n",
       "25                                  Major Lazer              3.22   \n",
       "26                                   Ed Sheeran              3.19   \n",
       "27                                 Taylor Swift              3.18   \n",
       "28                                      Shakira              3.17   \n",
       "29                                     J Balvin              3.10   \n",
       "\n",
       "          upload_date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3    January 30, 2017  \n",
       "4       April 6, 2015  \n",
       "5         May 2, 2018  \n",
       "6       March 6, 2014  \n",
       "7   November 19, 2014  \n",
       "8   February 27, 2018  \n",
       "9    January 31, 2012  \n",
       "10      July 15, 2012  \n",
       "11       May 24, 2018  \n",
       "12      April 5, 2018  \n",
       "13   January 14, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16   October 22, 2015  \n",
       "17    October 7, 2014  \n",
       "18      June 16, 2009  \n",
       "19       May 31, 2018  \n",
       "20   December 3, 2015  \n",
       "21  February 20, 2014  \n",
       "22      June 25, 2018  \n",
       "23      July 25, 2012  \n",
       "24     April 11, 2014  \n",
       "25     March 22, 2015  \n",
       "26   November 9, 2017  \n",
       "27    August 18, 2014  \n",
       "28       June 4, 2010  \n",
       "29      June 29, 2017  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a diction of all the columns\n",
    "dict = {'rank':rank, 'video_name':video_names,'uploader':video_uploader_name,'Views in Billions':views,'upload_date':upload_dates}\n",
    "# CREATING TABLE / dATA fRAME OF THE DICTIONARY\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91a790",
   "metadata": {},
   "source": [
    "# Q.6 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details: A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff30573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0674e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51964090",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ff12bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = []\n",
    "artist = []\n",
    "last_week_rank = []\n",
    "peak_rank = []\n",
    "weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63253d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SONG NAME ELEMENT EXTRACTION\n",
    "try:\n",
    "    song_name_obj = driver.find_elements_by_xpath('//span[@class=\"chart-element__information\"]/span[1]')\n",
    "   \n",
    "    for i in range(len(song_name_obj)):\n",
    "        song.append(song_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    song.append('-')\n",
    "    \n",
    "    \n",
    "#ARTIST NAME ELEMENT EXTRACTION\n",
    "try:\n",
    "   \n",
    "    singer_name_obj = driver.find_elements_by_xpath('//span[@class=\"chart-element__information\"]/span[2]')\n",
    "    for i in range(len(singer_name_obj)):\n",
    "        \n",
    "        artist.append(singer_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    artist.append('-')\n",
    "    \n",
    "    \n",
    "#LAST WEEK RANK of a SONG  ELEMENT EXTRACTION    \n",
    "    #chart-element__metas chart-element__metas--large display--flex flex--y-center\n",
    "try:\n",
    "    rank_lastweek_obj = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "   \n",
    "    for i in range(len(rank_lastweek_obj)):\n",
    "        last_week_rank.append(rank_lastweek_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    last_week_rank.append('-')\n",
    "    \n",
    "    \n",
    "#PEAK RANK OF A SONG ELEMENT EXTRACTION    \n",
    "try:\n",
    "   \n",
    "    peak_rank_obj = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "    for i in range(len(peak_rank_obj)):\n",
    "        \n",
    "        peak_rank.append(peak_rank_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "     peak_rank.append('-')  \n",
    "\n",
    "#WEEKS ON BOARD for a SONG ELEMENT EXTRACTION\n",
    "try:\n",
    "   \n",
    "    no_of_weeks_onboard_obj = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "    for i in range(len(no_of_weeks_onboard_obj)):\n",
    "        \n",
    "        weeks_on_board.append(no_of_weeks_onboard_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    weeks_on_board.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67013bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>last_week_rank</th>\n",
       "      <th>peak_rank</th>\n",
       "      <th>no_of_weeks_onboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [song_name, artist_name, last_week_rank, peak_rank, no_of_weeks_onboard]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    'song_name': song, 'artist_name':artist,\n",
    "    'last_week_rank': last_week_rank,'peak_rank':peak_rank,'no_of_weeks_onboard': weeks_on_board\n",
    "}\n",
    "table = pd.DataFrame(dict)\n",
    "table\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cc365",
   "metadata": {},
   "source": [
    "# Q7 .Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details: A) Name B) Designation C) Company D) Skills they hire for E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d9a3313",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//ul[@class='midSec menu']/li[2]/a\"}\n  (Session info: chrome=103.0.5060.53)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00396463+2188387]\n\tOrdinal0 [0x0032E461+1762401]\n\tOrdinal0 [0x00243D78+802168]\n\tOrdinal0 [0x00271880+989312]\n\tOrdinal0 [0x00271B1B+989979]\n\tOrdinal0 [0x0029E912+1173778]\n\tOrdinal0 [0x0028C824+1099812]\n\tOrdinal0 [0x0029CC22+1166370]\n\tOrdinal0 [0x0028C5F6+1099254]\n\tOrdinal0 [0x00266BE0+945120]\n\tOrdinal0 [0x00267AD6+948950]\n\tGetHandleVerifier [0x006371F2+2712546]\n\tGetHandleVerifier [0x0062886D+2652765]\n\tGetHandleVerifier [0x0042002A+520730]\n\tGetHandleVerifier [0x0041EE06+516086]\n\tOrdinal0 [0x0033468B+1787531]\n\tOrdinal0 [0x00338E88+1805960]\n\tOrdinal0 [0x00338F75+1806197]\n\tOrdinal0 [0x00341DF1+1842673]\n\tBaseThreadInitThunk [0x75EB6359+25]\n\tRtlGetAppContainerNamedObjectPath [0x774F87A4+228]\n\tRtlGetAppContainerNamedObjectPath [0x774F8774+180]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11760/2731614602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Let's navigate and clciking on the recruiter option on the search pane\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrecruiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//ul[@class='midSec menu']/li[2]/a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecruiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         )\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1249\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//ul[@class='midSec menu']/li[2]/a\"}\n  (Session info: chrome=103.0.5060.53)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00396463+2188387]\n\tOrdinal0 [0x0032E461+1762401]\n\tOrdinal0 [0x00243D78+802168]\n\tOrdinal0 [0x00271880+989312]\n\tOrdinal0 [0x00271B1B+989979]\n\tOrdinal0 [0x0029E912+1173778]\n\tOrdinal0 [0x0028C824+1099812]\n\tOrdinal0 [0x0029CC22+1166370]\n\tOrdinal0 [0x0028C5F6+1099254]\n\tOrdinal0 [0x00266BE0+945120]\n\tOrdinal0 [0x00267AD6+948950]\n\tGetHandleVerifier [0x006371F2+2712546]\n\tGetHandleVerifier [0x0062886D+2652765]\n\tGetHandleVerifier [0x0042002A+520730]\n\tGetHandleVerifier [0x0041EE06+516086]\n\tOrdinal0 [0x0033468B+1787531]\n\tOrdinal0 [0x00338E88+1805960]\n\tOrdinal0 [0x00338F75+1806197]\n\tOrdinal0 [0x00341DF1+1842673]\n\tBaseThreadInitThunk [0x75EB6359+25]\n\tRtlGetAppContainerNamedObjectPath [0x774F87A4+228]\n\tRtlGetAppContainerNamedObjectPath [0x774F8774+180]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Let's activate and load the chrome browser\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Let's open the URL\n",
    "driver.get('https://www.naukri.com/')\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "# Let's navigate and clciking on the recruiter option on the search pane\n",
    "recruiter=driver.find_element_by_xpath(\"//ul[@class='midSec menu']/li[2]/a\")\n",
    "driver.get(recruiter.get_attribute('href'))\n",
    "time.sleep(5)\n",
    "# Let's navigate to the search bar and Type Data Science in the search bar and click search\n",
    "search_field_designation=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search_field_designation.send_keys(\"Data Science\")\n",
    "driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()\n",
    "time.sleep(5)\n",
    "# Let's create an empty lists to store the scraping data\n",
    "Name=[]\n",
    "Designation=[] \n",
    "Company=[] \n",
    "Skills_they_hire_for=[] \n",
    "Location=[]\n",
    "\n",
    "# Scrape the data as metioned in question\n",
    "try:\n",
    "    name = driver.find_elements_by_xpath('//span[@class=\"fl ellipsis\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Name element N/a\")\n",
    "\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except:\n",
    "        Name.append('--')\n",
    "try:\n",
    "    designation = driver.find_elements_by_xpath('//span[@class=\"ellipsis clr\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Designation element N/a\")\n",
    "\n",
    "for i in designation:\n",
    "    try:\n",
    "        Designation.append(i.text)\n",
    "    except:\n",
    "        Designation.append('--')\n",
    "try:\n",
    "    company = driver.find_elements_by_xpath('//p[@class=\"highlightable\"]/a[2]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Company element N/a\")\n",
    "\n",
    "for i in company:\n",
    "    try:\n",
    "        Company.append(i.text)\n",
    "    except:\n",
    "        Company.append('--')\n",
    "try:\n",
    "    skill = driver.find_elements_by_xpath('//div[@class=\"hireSec highlightable\"]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Skill element N/a\")\n",
    "\n",
    "for i in skill:\n",
    "    try:\n",
    "        Skills_they_hire_for.append(i.text)\n",
    "    except:\n",
    "        Skills_they_hire_for.append('--')\n",
    "try:\n",
    "    loc = driver.find_elements_by_xpath('//p[@class=\"highlightable\"]/span[2]')\n",
    "except NoSuchElementException:\n",
    "    print(\"Location element N/a\")\n",
    "\n",
    "for i in loc:\n",
    "    try:\n",
    "        Location.append(i.text)\n",
    "    except NoSuchElementException:        \n",
    "        Location.append(\"---\")\n",
    "# Let's check the length of the scrape data\n",
    "print(len(Name),len(Designation),len(Company),len(Skills_they_hire_for),len(Location))\n",
    "\n",
    "\n",
    "# Let's create the dataframe from the scraped data\n",
    "Data_Science=pd.DataFrame({})\n",
    "Data_Science['Name']=Name[0:45]\n",
    "Data_Science['Designation']=Designation[0:45]\n",
    "Data_Science['Company']=Company[0:45]\n",
    "Data_Science['Skills they Hire for']= Skills_they_hire_for[0:45]\n",
    "Data_Science['Location']=Location[0:45]\n",
    "Data_Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334239bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
